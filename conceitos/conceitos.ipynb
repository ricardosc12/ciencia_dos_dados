{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Regras de associação\n",
        "\n",
        "Regras de associação são usadas para descobrir relações interessantes ou padrões frequentes em conjuntos de dados. Elas são compostas por uma parte antecedente (ou \"antecedente\") e uma parte consequente (ou \"consequente\"). Essas regras são usadas para identificar associações entre diferentes itens ou variáveis em um conjunto de dados.\n",
        "\n",
        "O algoritmo Apriori é uma técnica clássica para a descoberta de regras de associação. Ele utiliza o conceito de suporte e confiança para encontrar as regras mais relevantes em um conjunto de dados.\n",
        "\n",
        "**Suporte**: O suporte de um conjunto de itens é definido como a frequência com que esse conjunto de itens aparece no conjunto de transações. É uma medida de quão popular ou frequente um conjunto de itens é. O suporte é calculado como a proporção de transações que contêm o conjunto de itens. Valores mais altos de suporte indicam maior frequência do conjunto de itens.\n",
        "\n",
        "**Confiança**: A confiança de uma regra de associação mede a probabilidade condicional de que o consequente ocorra dado o antecedente. Ela é calculada como a proporção de transações que contêm o antecedente e o consequente em relação às transações que contêm apenas o antecedente. A confiança indica a força da relação entre o antecedente e o consequente. Valores mais altos de confiança indicam maior probabilidade de ocorrência do consequente dado o antecedente.\n",
        "\n",
        "**Lift**: O lift é uma métrica que mede a força de uma regra de associação em relação à ocorrência conjunta do antecedente e do consequente, em comparação com a ocorrência esperada se eles fossem independentes. O lift é calculado como a razão entre a confiança da regra e o suporte do consequente. Um lift maior que 1 indica que o antecedente e o consequente ocorrem juntos com mais frequência do que o esperado de forma independente, o que indica uma associação positiva.\n",
        "\n",
        "**Como calcular no arquivo de revisão.**\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Regressão linear\n",
        "\n",
        "A regressão linear tem como objetivo encontrar a melhor linha reta que represente a relação entre as variáveis independentes (também chamadas de variáveis preditoras) e a variável dependente. Essa linha é definida pela equação:\n",
        "\n",
        "#### y = b0 + b1*x1 + b2*x2 + ... + bn*xn\n",
        "\n",
        "- y é a variável dependente que estamos tentando prever.\n",
        "- x1, x2, ..., xn são as variáveis independentes.\n",
        "- b0, b1, b2, ..., bn são os coeficientes que multiplicam as variáveis independentes e representam a inclinação da linha.\n",
        "\n",
        "**Coeficiente de Determinação (R²)**: É uma métrica que indica o quanto a variabilidade da variável dependente pode ser explicada pelas variáveis independentes. O valor de R² varia de 0 a 1, onde 1 significa que o modelo é capaz de explicar totalmente a variabilidade dos dados e 0 significa que o modelo não é capaz de explicar nada. Quanto maior o valor de R², melhor o modelo se ajusta aos dados.\n",
        "\n",
        "**Resíduos**: Os resíduos são as diferenças entre os valores reais (y) e os valores previstos (y_pred). Representam a discrepância entre o modelo e os dados reais. Um bom modelo de regressão linear terá resíduos próximos de zero, indicando que o modelo está capturando bem os padrões nos dados.\n",
        "\n",
        "**Pressupostos da Regressão Linear**: A regressão linear faz certas suposições sobre os dados, incluindo: linearidade, independência dos resíduos, homocedasticidade (variância constante dos resíduos), normalidade dos resíduos e ausência de multicolinearidade (alta correlação entre as variáveis independentes). É importante verificar se essas suposições são atendidas antes de usar a regressão linear e, se necessário, aplicar técnicas de pré-processamento ou usar outras formas de regressão.\n",
        "\n",
        "**Métodos de Avaliação**: Além do coeficiente de determinação (R²), existem várias métricas para avaliar a qualidade do modelo de regressão linear, como o erro médio quadrático (RMSE) e o erro absoluto médio (MAE). Essas métricas medem a diferença entre os valores reais e os valores previstos."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Aprendizado supervisionado\n",
        "\n",
        "O aprendizado supervisionado é um ramo do aprendizado de máquina em que um modelo é treinado usando um conjunto de dados rotulados. Nesse tipo de aprendizado, o modelo aprende a mapear os dados de entrada para uma variável de saída com base nos exemplos fornecidos durante o treinamento. O objetivo é que o modelo seja capaz de fazer previsões precisas em novos dados não rotulados.\n",
        "\n",
        "**Classificação**: Na classificação, o objetivo é prever uma variável de saída categórica ou discreta. O modelo aprende a classificar os dados em diferentes classes ou categorias com base nos exemplos de treinamento. Por exemplo, classificar e-mails como spam ou não spam, prever se um paciente tem uma determinada doença com base em sintomas, etc.\n",
        "\n",
        "**Regressão**: Na regressão, o objetivo é prever uma variável de saída contínua ou numérica. O modelo aprende a estabelecer uma relação entre os dados de entrada e a variável de saída para fazer previsões. Por exemplo, prever o preço de uma casa com base em características como área, número de quartos, etc., prever a demanda de vendas com base em fatores como preço, publicidade, etc.\n",
        "\n",
        "**Avaliação do modelo**:\n",
        "Após o treinamento, o modelo é avaliado usando o conjunto de teste. Métricas de desempenho, como acurácia, precisão, recall, F1-score, MSE (Mean Squared Error) ou R², são calculadas para medir o quão bem o modelo está fazendo previsões nos dados não vistos.\n",
        "\n",
        "\n",
        "- **Acurácia**: A acurácia é uma métrica básica que mede a taxa de acertos do modelo. É calculada como a proporção de exemplos classificados corretamente em relação ao total de exemplos. A acurácia é adequada quando as classes estão balanceadas, ou seja, têm uma distribuição semelhante no conjunto de dados. No entanto, pode não ser uma métrica adequada quando as classes estão desbalanceadas.\n",
        "\n",
        "- **Precisão**: A precisão mede a proporção de exemplos positivos corretamente classificados em relação a todos os exemplos classificados como positivos (incluindo falsos positivos). Ela é útil quando o foco está em minimizar os falsos positivos, ou seja, quando classificar erroneamente um exemplo negativo como positivo tem um impacto significativo.\n",
        "\n",
        "- **Recall** (Revocação): O recall mede a proporção de exemplos positivos corretamente classificados em relação a todos os exemplos que realmente são positivos (incluindo falsos negativos). O recall é relevante quando o foco está em minimizar os falsos negativos, ou seja, quando classificar erroneamente um exemplo positivo como negativo tem um impacto significativo.\n",
        "\n",
        "- **F1-score**: O F1-score é uma medida de equilíbrio entre a precisão e o recall. Ele é calculado como a média harmônica entre a precisão e o recall. O F1-score é útil quando se deseja ter um equilíbrio entre a minimização de falsos positivos e falsos negativos.\n",
        "\n",
        "- **Matriz de Confusão**: A matriz de confusão é uma tabela que mostra a contagem de exemplos classificados em cada classe versus sua classe real. Ela é usada para visualizar o desempenho do modelo de classificação. A partir da matriz de confusão, é possível calcular métricas como acurácia, precisão, recall e F1-score.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Aprendizado não supervionado\n",
        "\n",
        "O aprendizado de máquina não supervisionado é uma abordagem do aprendizado de máquina em que não há rótulos ou variáveis de saída conhecidas nos dados de entrada. Em vez disso, o objetivo é descobrir estruturas, padrões e relacionamentos ocultos nos dados, sem a orientação de rótulos pré-existentes. É uma forma de exploração de dados em que o modelo busca entender a organização dos dados por conta própria.\n",
        "\n",
        "**Agrupamento (Clustering)**: O agrupamento é uma técnica usada para dividir os dados em grupos ou clusters com base em sua similaridade. O objetivo é que os dados dentro do mesmo cluster sejam mais semelhantes entre si do que com os dados de outros clusters. Alguns algoritmos populares de agrupamento incluem o k-means, o DBSCAN (Density-Based Spatial Clustering of Applications with Noise) e o hierarchical clustering.\n",
        "\n",
        "**Análise de Componentes Principais (PCA)**: O PCA é uma técnica usada para reduzir a dimensionalidade dos dados, encontrando as direções de maior variância nos dados e projetando-os em um espaço de menor dimensão. Ele ajuda a identificar os principais componentes que explicam a variabilidade dos dados. O PCA é útil para visualização de dados de alta dimensionalidade e para remover redundâncias e ruídos dos dados.\n",
        "\n",
        "**Redes Neurais Não Supervisionadas**: As redes neurais não supervisionadas, como as Redes Neurais Autoencoder e as Restricted Boltzmann Machines (RBM), são modelos que aprendem a extrair características significativas dos dados de entrada sem rótulos. Essas redes têm uma arquitetura especializada que permite aprender representações latentes dos dados, que podem ser posteriormente usadas para outras tarefas, como classificação ou reconstrução de imagens.\n",
        "\n",
        "#### **Clusterização (Clustering)**:\n",
        "A clusterização é uma técnica de aprendizado não supervisionado que visa dividir os dados em grupos ou clusters, de forma que os objetos dentro do mesmo cluster sejam similares entre si, enquanto objetos de clusters diferentes sejam distintos. Existem diversos algoritmos de clusterização, sendo alguns dos mais populares:\n",
        "\n",
        "- **K-means**: O algoritmo K-means é um método de particionamento que agrupa os dados em k clusters, onde k é um valor definido previamente. Ele minimiza a soma dos quadrados das distâncias entre os objetos e seus respectivos centroides de cluster. O K-means é amplamente utilizado devido à sua simplicidade e eficiência, mas é sensível à escolha inicial dos centroides.\n",
        "\n",
        "- **DBSCAN**: O algoritmo DBSCAN é baseado em densidade e pode encontrar clusters de forma automática, sem a necessidade de especificar previamente o número de clusters. Ele agrupa os pontos que estão densamente conectados e os separa das regiões menos densas. O DBSCAN é robusto a ruídos e pode identificar clusters de diferentes formas e tamanhos.\n",
        "\n",
        "- **Hierarchical Clustering (Aglomerativo e Divisivo)**: O hierarchical clustering é um método que cria uma hierarquia de clusters, começando com cada objeto como seu próprio cluster e, em seguida, combinando clusters gradualmente até que todos os objetos estejam em um único cluster (divisivo) ou todos os objetos estejam em um único cluster inicial (aglomerativo). Esse método produz uma árvore hierárquica chamada dendrograma, que pode ser cortado em diferentes níveis para obter diferentes partições.\n",
        "\n",
        "#### **Métricas de Avaliação de Clusterização**:\n",
        "A avaliação dos resultados da clusterização é essencial para entender a qualidade e a interpretação dos clusters encontrados. Aqui estão algumas métricas comumente utilizadas para avaliar a qualidade dos clusters:\n",
        "\n",
        "- **Coeficiente de Silhueta (Silhouette Coefficient)**: O coeficiente de silhueta mede a qualidade de um cluster com base na distância média entre um objeto e os objetos do mesmo cluster em relação à distância média entre o objeto e os objetos de outros clusters. Ele varia de -1 a 1, onde um valor mais próximo de 1 indica que o objeto está bem atribuído ao seu cluster e está distante dos objetos de outros clusters.\n",
        "\n",
        "- **Índice de Calinski-Harabasz (Calinski-Harabasz Index)**: O índice de Calinski-Harabasz é uma métrica que avalia a separação entre os clusters e a compactação dentro dos clusters. Quanto maior o valor do índice, melhor a qualidade da clusterização. Ele é calculado como a razão entre a soma da dispersão entre os clusters e a soma da dispersão dentro dos clusters.\n",
        "\n",
        "- **Índice Davies-Bouldin (Davies-Bouldin Index)**: O índice Davies-Bouldin mede a separação entre os clusters e a compactação dentro dos clusters. Quanto menor o valor do índice, melhor a qualidade da clusterização. Ele é calculado como a média das distâncias entre cada par de clusters, ponderada pela soma das distâncias entre os centroides dos\n",
        "\n",
        "\n",
        "#### Métricas para avaliação de Clusterização gerada em comparação a Real\n",
        "\n",
        "- **Índice de Rand Ajustado (Adjusted Rand Index - ARI)**: O ARI é uma métrica que mede a similaridade entre duas atribuições de clusters, levando em consideração todas as possíveis combinações de pares de objetos e clusters. Ele retorna um valor entre -1 e 1, em que 1 indica uma concordância perfeita entre as atribuições de clusters e -1 indica uma discordância completa. Valores próximos a 0 indicam atribuições aleatórias. O ARI é robusto a diferentes tamanhos de clusters e é amplamente utilizado para avaliar a qualidade da clusterização.\n",
        "\n",
        "- **Índice de Pureza (Purity)**: A pureza é uma métrica simples que mede o quão puros são os clusters em relação às classes reais. Ela calcula a proporção de objetos do cluster que pertencem à classe majoritária. A pureza varia de 0 a 1, onde 1 indica que todos os objetos em cada cluster pertencem à mesma classe. No entanto, a pureza não considera as atribuições de clusters entre as classes, portanto, pode ser enganosa quando as classes têm sobreposição nos clusters.\n",
        "\n",
        "- **Jaccard**: O coeficiente de similaridade de Jaccard também é uma métrica comumente utilizada para avaliar a qualidade da clusterização em problemas não supervisionados. O coeficiente de similaridade de Jaccard mede a sobreposição entre dois conjuntos. No contexto da clusterização, pode ser aplicado para medir a similaridade entre os objetos atribuídos a um mesmo cluster."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "interpreter": {
      "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
